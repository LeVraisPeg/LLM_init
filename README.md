# LLM_init

Un projet d'initiation au LLM avec des exercices pratiques pour comprendre et manipuler des mod√®les de langage.

## üìã Description

Ce repository contient deux notebooks Jupyter qui vous guideront √† travers les bases de l'IA g√©n√©rative en manipulant et en contr√¥lant un LLM install√© en local.

## Contenu

### 1. Copie_de_TP_initiation_llm.ipynb
Notebook principal qui couvre :
- Installation des d√©pendances (transformers, torch)
- Chargement du mod√®le FLAN-T5
- Tokenisation et d√©codage de texte
- Interrogation basique du LLM
- R√©sum√© de dialogues avec le dataset DialogSum
- Techniques de prompt engineering (zero-shot, one-shot, few-shot)

### 2. MyLLM.ipynb
# Mini-projet ‚Äî Syst√®me de Questions-R√©ponses avec √âvaluation Automatique

## Objectif
L‚Äôobjectif de ce mini-projet est de concevoir un syst√®me de questions-r√©ponses bas√© sur un mod√®le de langage (LLM) appliqu√© √† un domaine sp√©cifique (le cin√©ma), et d‚Äô√©valuer automatiquement la qualit√© des r√©ponses g√©n√©r√©es selon diff√©rentes strat√©gies de prompting.

---

## Description du projet
Le projet s‚Äôarticule autour de trois axes principaux :

1. **Cr√©ation d‚Äôun dataset**
   - √âlaboration d‚Äôun jeu de donn√©es de 15 questions-r√©ponses portant sur des notions fondamentales du cin√©ma.
   - Chaque question est associ√©e √† une r√©ponse de r√©f√©rence servant de base pour l‚Äô√©valuation.

2. **G√©n√©ration de r√©ponses avec un LLM**
   - Utilisation du mod√®le **Qwen2.5-3B-Instruct** via la biblioth√®que Transformers.
   - Comparaison de trois approches de prompting :
     - **Zero-shot** : aucune d√©monstration fournie
     - **One-shot** : une paire question-r√©ponse en exemple
     - **Few-shot** : plusieurs paires question-r√©ponse en exemple
   - Test de diff√©rentes configurations de g√©n√©ration (temp√©rature, top_p, top_k).

3. **√âvaluation automatique de la qualit√©**
   - Calcul d‚Äôun score combinant :
     - la similarit√© s√©mantique entre la r√©ponse g√©n√©r√©e et la r√©ponse de r√©f√©rence (embeddings),
     - une contrainte sur la longueur de la r√©ponse.
   - Comparaison des performances des approches en termes de qualit√© moyenne et de robustesse.

---

## M√©thodologie
- Domaine : cin√©ma  
- Nombre de questions : 15  
- Mod√®le de langage : Qwen2.5-3B-Instruct  
- Approches test√©es : zero-shot, one-shot, few-shot  
- √âvaluation : score automatique (similarit√© s√©mantique + ratio de longueur)

---

## Technologies utilis√©es
- Python
- Transformers (Hugging Face)
- Sentence-Transformers
- PyTorch
- Matplotlib


